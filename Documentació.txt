importació_data.py:
    read_ts_data(
                path: str
                ) -> pd.DataFrame:
    
    read_all_ts_data(
                train_path: str = 'data_ts\sts_cat_train_v1.tsv', 
                test_path: str = 'data_ts\sts_cat_test_v1.tsv', 
                val_path: str = 'data_ts\sts_cat_dev_v1.tsv' 
                ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:

    reformat_data(
                train: pd.DataFrame, 
                test: pd.DataFrame, 
                val: pd.DataFrame
                ) -> Tuple[List[Tuple[str, str, float]], List[Tuple[str, str, float]], List[Tuple[str, str, float]]]:
    
    create_corpus(
                input_pairs: List[Tuple[str, str, float]], 
                input_pairs_val: List[Tuple[str, str, float]], 
                input_pairs_test: List[Tuple[str, str, float]], 
                preprocess: Callable = simple_preprocess
                ) -> List[List[Tuple[int, int]]]:
    
    stopwords_cat(
                path_stopwords: str = 'data_ts/stopwords_cat.txt'
                ) -> set:
    
    preprocess(
                sentence: str, 
                stopwords: set = stopwords_cat()
                ) -> List[str]:

model_bàsic.py:
    def model_ts(
                    input_length: int = MAX_LEN,
                    dictionary_size: int = 1000,
                    embedding_size: int = 16,
                    learning_rate: float = 1e-3,
                    pretrained_weights: Optional[np.ndarray] = None,
                    trainable: bool = False,
                    use_cosine: bool = False,
                ) -> tf.keras.Model: