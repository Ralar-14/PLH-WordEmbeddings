{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-trf==3.7.2\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_trf-3.7.2/ca_core_news_trf-3.7.2-py3-none-any.whl (457.1 MB)\n",
      "     ---------------------------------------- 0.0/457.1 MB ? eta -:--:--\n",
      "     -------------------------------------- 0.0/457.1 MB 320.0 kB/s eta 0:23:49\n",
      "     -------------------------------------- 0.1/457.1 MB 777.7 kB/s eta 0:09:48\n",
      "     ---------------------------------------- 0.6/457.1 MB 5.0 MB/s eta 0:01:32\n",
      "     ---------------------------------------- 1.4/457.1 MB 8.1 MB/s eta 0:00:57\n",
      "     --------------------------------------- 2.4/457.1 MB 10.7 MB/s eta 0:00:43\n",
      "     --------------------------------------- 3.5/457.1 MB 12.9 MB/s eta 0:00:36\n",
      "     --------------------------------------- 4.8/457.1 MB 15.4 MB/s eta 0:00:30\n",
      "      -------------------------------------- 6.4/457.1 MB 17.8 MB/s eta 0:00:26\n",
      "      -------------------------------------- 8.4/457.1 MB 20.6 MB/s eta 0:00:22\n",
      "      ------------------------------------- 10.6/457.1 MB 29.7 MB/s eta 0:00:16\n",
      "     - ------------------------------------ 13.6/457.1 MB 43.7 MB/s eta 0:00:11\n",
      "     - ------------------------------------ 15.9/457.1 MB 50.4 MB/s eta 0:00:09\n",
      "     - ------------------------------------ 20.7/457.1 MB 73.1 MB/s eta 0:00:06\n",
      "     -- ----------------------------------- 24.1/457.1 MB 72.6 MB/s eta 0:00:06\n",
      "     -- ---------------------------------- 28.5/457.1 MB 110.0 MB/s eta 0:00:04\n",
      "     -- ----------------------------------- 31.9/457.1 MB 93.9 MB/s eta 0:00:05\n",
      "     -- ----------------------------------- 35.7/457.1 MB 93.9 MB/s eta 0:00:05\n",
      "     --- ---------------------------------- 41.0/457.1 MB 93.9 MB/s eta 0:00:05\n",
      "     --- --------------------------------- 45.5/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ---- -------------------------------- 50.3/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ---- -------------------------------- 54.7/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ---- --------------------------------- 59.6/457.1 MB 93.9 MB/s eta 0:00:05\n",
      "     ----- -------------------------------- 64.4/457.1 MB 93.9 MB/s eta 0:00:05\n",
      "     ----- ------------------------------- 68.3/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ----- ------------------------------- 73.4/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ------ ------------------------------ 78.5/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ------ ------------------------------ 82.7/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ------- ------------------------------ 87.4/457.1 MB 93.9 MB/s eta 0:00:04\n",
      "     ------- ----------------------------- 93.1/457.1 MB 129.5 MB/s eta 0:00:03\n",
      "     ------- ----------------------------- 96.3/457.1 MB 110.0 MB/s eta 0:00:04\n",
      "     -------- ----------------------------- 97.9/457.1 MB 81.8 MB/s eta 0:00:05\n",
      "     -------- ---------------------------- 104.3/457.1 MB 81.8 MB/s eta 0:00:05\n",
      "     -------- --------------------------- 109.8/457.1 MB 131.2 MB/s eta 0:00:03\n",
      "     -------- --------------------------- 113.4/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     --------- -------------------------- 118.2/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     --------- -------------------------- 123.6/457.1 MB 131.2 MB/s eta 0:00:03\n",
      "     ---------- ------------------------- 127.3/457.1 MB 108.8 MB/s eta 0:00:04\n",
      "     ---------- -------------------------- 129.9/457.1 MB 93.9 MB/s eta 0:00:04\n",
      "     ---------- -------------------------- 132.9/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ----------- ------------------------- 137.6/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ----------- ------------------------- 141.1/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ----------- ------------------------- 144.4/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ----------- ------------------------- 147.3/457.1 MB 72.6 MB/s eta 0:00:05\n",
      "     ------------ ------------------------ 151.4/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ------------ ------------------------ 155.3/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ------------ ------------------------ 159.1/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ------------- ----------------------- 164.0/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ------------- ----------------------- 167.7/457.1 MB 93.9 MB/s eta 0:00:04\n",
      "     ------------- ----------------------- 170.4/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     -------------- ---------------------- 175.4/457.1 MB 93.0 MB/s eta 0:00:04\n",
      "     -------------- ---------------------- 178.7/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     -------------- ---------------------- 182.0/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     -------------- ---------------------- 182.1/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     -------------- ---------------------- 185.2/457.1 MB 54.7 MB/s eta 0:00:05\n",
      "     --------------- --------------------- 185.7/457.1 MB 43.7 MB/s eta 0:00:07\n",
      "     --------------- --------------------- 186.8/457.1 MB 40.9 MB/s eta 0:00:07\n",
      "     --------------- --------------------- 190.4/457.1 MB 40.9 MB/s eta 0:00:07\n",
      "     --------------- --------------------- 191.0/457.1 MB 36.4 MB/s eta 0:00:08\n",
      "     --------------- --------------------- 193.2/457.1 MB 38.5 MB/s eta 0:00:07\n",
      "     --------------- --------------------- 195.8/457.1 MB 43.7 MB/s eta 0:00:06\n",
      "     ---------------- -------------------- 200.0/457.1 MB 50.4 MB/s eta 0:00:06\n",
      "     ---------------- -------------------- 202.9/457.1 MB 81.8 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 205.5/457.1 MB 73.1 MB/s eta 0:00:04\n",
      "     ---------------- -------------------- 207.8/457.1 MB 59.5 MB/s eta 0:00:05\n",
      "     ----------------- ------------------- 212.2/457.1 MB 59.5 MB/s eta 0:00:05\n",
      "     ----------------- ------------------- 213.2/457.1 MB 65.6 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 213.2/457.1 MB 65.6 MB/s eta 0:00:04\n",
      "     ----------------- ------------------- 214.7/457.1 MB 38.6 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 217.8/457.1 MB 43.7 MB/s eta 0:00:06\n",
      "     ----------------- ------------------- 219.5/457.1 MB 38.6 MB/s eta 0:00:07\n",
      "     ----------------- ------------------- 221.7/457.1 MB 36.4 MB/s eta 0:00:07\n",
      "     ------------------ ------------------ 227.1/457.1 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 230.0/457.1 MB 72.6 MB/s eta 0:00:04\n",
      "     ------------------ ------------------ 233.7/457.1 MB 81.8 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 236.7/457.1 MB 72.6 MB/s eta 0:00:04\n",
      "     ------------------- ----------------- 239.6/457.1 MB 73.1 MB/s eta 0:00:03\n",
      "     ------------------- ----------------- 242.1/457.1 MB 65.6 MB/s eta 0:00:04\n",
      "     ------------------- ----------------- 244.9/457.1 MB 59.5 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 247.9/457.1 MB 59.5 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 251.8/457.1 MB 65.6 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 254.2/457.1 MB 59.5 MB/s eta 0:00:04\n",
      "     -------------------- ---------------- 257.7/457.1 MB 65.2 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 260.2/457.1 MB 65.2 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 263.4/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     --------------------- --------------- 266.2/457.1 MB 59.5 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 269.1/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 272.9/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 275.1/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 278.5/457.1 MB 59.8 MB/s eta 0:00:03\n",
      "     ---------------------- -------------- 282.2/457.1 MB 72.6 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 284.3/457.1 MB 65.2 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 286.2/457.1 MB 59.8 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 291.4/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 294.2/457.1 MB 73.1 MB/s eta 0:00:03\n",
      "     ----------------------- ------------- 294.5/457.1 MB 54.7 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 296.6/457.1 MB 59.5 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 300.2/457.1 MB 50.4 MB/s eta 0:00:04\n",
      "     ------------------------ ------------ 303.2/457.1 MB 50.4 MB/s eta 0:00:04\n",
      "     ------------------------ ------------ 306.7/457.1 MB 72.6 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 309.6/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 312.6/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 316.1/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 320.0/457.1 MB 72.6 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 322.3/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 325.5/457.1 MB 65.6 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 328.7/457.1 MB 65.2 MB/s eta 0:00:02\n",
      "     -------------------------- ---------- 331.9/457.1 MB 65.2 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 335.3/457.1 MB 73.1 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 338.3/457.1 MB 65.6 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 340.1/457.1 MB 59.5 MB/s eta 0:00:02\n",
      "     --------------------------- --------- 345.7/457.1 MB 72.6 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 348.2/457.1 MB 72.6 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 351.5/457.1 MB 81.8 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 354.7/457.1 MB 72.6 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 356.6/457.1 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 356.6/457.1 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 356.6/457.1 MB 73.1 MB/s eta 0:00:02\n",
      "     ---------------------------- -------- 358.3/457.1 MB 36.4 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 360.5/457.1 MB 34.4 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 366.5/457.1 MB 38.5 MB/s eta 0:00:03\n",
      "     ----------------------------- ------ 370.7/457.1 MB 108.8 MB/s eta 0:00:01\n",
      "     ------------------------------ ------ 373.2/457.1 MB 81.8 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 378.0/457.1 MB 73.1 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 381.3/457.1 MB 72.6 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 384.5/457.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 388.6/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 390.3/457.1 MB 59.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 395.6/457.1 MB 81.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 399.0/457.1 MB 73.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 402.4/457.1 MB 81.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 404.7/457.1 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 408.8/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 412.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 414.5/457.1 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 419.7/457.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 422.8/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 426.0/457.1 MB 73.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 430.0/457.1 MB 73.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 433.7/457.1 MB 73.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 435.3/457.1 MB 59.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 437.1/457.1 MB 54.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 442.4/457.1 MB 59.5 MB/s eta 0:00:01\n",
      "     -----------------------------------  447.2/457.1 MB 108.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  449.7/457.1 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  454.6/457.1 MB 93.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  457.1/457.1 MB 72.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 457.1/457.1 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from ca-core-news-trf==3.7.2) (3.7.4)\n",
      "Requirement already satisfied: spacy-curated-transformers<0.3.0,>=0.2.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from ca-core-news-trf==3.7.2) (0.2.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.26.4)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2024.5.15)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (3.14.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-trf==3.7.2) (1.1.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (2021.12.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ralva\\desktop\\university\\4t-cuatrimestre-gia\\plh\\plh-wordembeddings\\wordembeddings\\lib\\site-packages (from sympy->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->ca-core-news-trf==3.7.2) (1.3.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ca_core_news_trf')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ca_core_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Optional\n",
    "import spacy\n",
    "import numpy as np\n",
    "from model_bàsic import build_and_compile_model_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de spaCy con integración de transformers para catalán\n",
    "roberta_model = spacy.load(\"ca_core_news_trf\")\n",
    "\n",
    "def get_roberta_embedding(text):\n",
    "    return np.mean(roberta_model(text)._.trf_data.last_hidden_layer_state.data[:-1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pairs(\n",
    "    sentence_pairs: List[Tuple[str, str, float]],\n",
    ") -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "    # Mapeo de los pares de oraciones a pares de vectores\n",
    "    pares_vectores = []\n",
    "    for i, (sentence_1, sentence_2, similitud) in enumerate(sentence_pairs):\n",
    "        vector1 = get_roberta_embedding(sentence_1)\n",
    "        vector2 = get_roberta_embedding(sentence_2)\n",
    "        # Añadir a la lista\n",
    "        \n",
    "        pares_vectores.append(((vector1, vector2), similitud))\n",
    "    return pares_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importació_data import read_all_ts_data, reformat_data\n",
    "\n",
    "# Get data\n",
    "train, val, test = read_all_ts_data()\n",
    "\n",
    "#Transform data\n",
    "train_pairs, val_pairs, test_pairs = reformat_data(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_train = map_pairs(train_pairs)\n",
    "mapped_val = map_pairs(val_pairs)\n",
    "mapped_test = map_pairs(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "from importació_data import pair_list_to_x_y\n",
    "\n",
    "X_train, y_train = pair_list_to_x_y(mapped_train)\n",
    "X_val, y_val = pair_list_to_x_y(mapped_val)\n",
    "X_test, y_test = pair_list_to_x_y(mapped_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │    \u001b[38;5;34m590,592\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_9[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m98,432\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m2,064\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">691,105</span> (2.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m691,105\u001b[0m (2.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">691,105</span> (2.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m691,105\u001b[0m (2.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_and_compile_model_better(768)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=((TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 768), dtype=tf.float32, name=None)), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.7260 - val_loss: 0.7254\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7177 - val_loss: 0.7222\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7147 - val_loss: 0.7194\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7070 - val_loss: 0.7190\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6909 - val_loss: 0.7211\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6802 - val_loss: 0.7243\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6650 - val_loss: 0.7286\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6546 - val_loss: 0.7336\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6518 - val_loss: 0.7378\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6308 - val_loss: 0.7399\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6252 - val_loss: 0.7531\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6229 - val_loss: 0.7519\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6089 - val_loss: 0.7599\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5966 - val_loss: 0.7658\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5947 - val_loss: 0.7691\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5851 - val_loss: 0.7808\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5812 - val_loss: 0.7780\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5687 - val_loss: 0.7839\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5656 - val_loss: 0.7732\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5662 - val_loss: 0.7934\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5553 - val_loss: 0.7922\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5479 - val_loss: 0.7924\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5414 - val_loss: 0.8222\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5300 - val_loss: 0.8223\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5343 - val_loss: 0.8017\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5270 - val_loss: 0.8060\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5201 - val_loss: 0.8098\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5281 - val_loss: 0.7977\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5301 - val_loss: 0.8324\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5081 - val_loss: 0.8163\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4929 - val_loss: 0.8292\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4927 - val_loss: 0.8300\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4876 - val_loss: 0.9095\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4840 - val_loss: 0.9787\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5148 - val_loss: 0.8176\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4846 - val_loss: 0.8433\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4960 - val_loss: 0.8222\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4844 - val_loss: 0.8290\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4733 - val_loss: 0.8010\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4738 - val_loss: 0.8295\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4712 - val_loss: 0.8317\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4641 - val_loss: 0.8274\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4717 - val_loss: 0.8066\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4514 - val_loss: 0.8117\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4550 - val_loss: 0.8278\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4461 - val_loss: 0.8246\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4717 - val_loss: 0.8674\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4625 - val_loss: 0.8448\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4573 - val_loss: 0.8877\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4464 - val_loss: 0.8616\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4364 - val_loss: 0.8369\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4301 - val_loss: 0.8403\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4148 - val_loss: 0.8836\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4259 - val_loss: 0.8395\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4354 - val_loss: 0.8330\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4589 - val_loss: 0.8377\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4246 - val_loss: 0.8657\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4249 - val_loss: 0.8786\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4267 - val_loss: 0.8551\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4186 - val_loss: 0.9118\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4122 - val_loss: 0.9848\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4143 - val_loss: 0.9197\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3999 - val_loss: 0.8643\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4140 - val_loss: 0.8530\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4076 - val_loss: 0.9343\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4004 - val_loss: 0.8788\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4333 - val_loss: 0.8629\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4288 - val_loss: 0.8682\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4057 - val_loss: 0.9256\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3908 - val_loss: 1.0115\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3914 - val_loss: 0.9567\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3780 - val_loss: 0.8811\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3782 - val_loss: 0.9235\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3860 - val_loss: 0.9646\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3927 - val_loss: 0.9143\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3925 - val_loss: 0.9517\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3874 - val_loss: 0.9090\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4040 - val_loss: 0.9028\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4073 - val_loss: 0.9212\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3839 - val_loss: 0.9128\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3750 - val_loss: 0.8755\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3826 - val_loss: 0.8578\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4018 - val_loss: 0.8497\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3911 - val_loss: 0.8544\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3930 - val_loss: 0.8302\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3965 - val_loss: 0.9163\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4019 - val_loss: 0.8375\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3962 - val_loss: 0.8784\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3758 - val_loss: 0.8468\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3886 - val_loss: 0.8768\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3891 - val_loss: 1.0070\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3659 - val_loss: 0.9903\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3768 - val_loss: 0.8682\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3631 - val_loss: 1.0184\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3576 - val_loss: 1.0032\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3696 - val_loss: 0.8596\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3978 - val_loss: 0.9490\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3556 - val_loss: 0.9341\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3409 - val_loss: 0.9403\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3608 - val_loss: 0.8787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x175518dce10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=100, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "x_test, y_test = pair_list_to_x_y(mapped_test)\n",
    "def compute_pearson(x_, y_, model):\n",
    "    # Get predictions for the model\n",
    "    y_pred = model.predict(x_)\n",
    "    # Compute pearson correlation\n",
    "    correlation, _ = pearsonr(y_pred.flatten(), y_.flatten())\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Correlación de Pearson (train): 0.7361164836771393\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Correlación de Pearson (validation): 0.15813986630961854\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Correlación de Pearson (test): 0.23395487116758615\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correlación de Pearson (train): {compute_pearson(X_train, y_train, model)}\")\n",
    "print(f\"Correlación de Pearson (validation): {compute_pearson(X_val, y_val, model)}\")\n",
    "print(f\"Correlación de Pearson (test): {compute_pearson(X_test, y_test, model)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WordEmbeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
